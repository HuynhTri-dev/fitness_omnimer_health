â— ğŸ¯ TÃ³m táº¯t: Giáº£i thÃ­ch chi tiáº¿t 4 bÆ°á»›c cáº£i tiáº¿n

TÃ´i Ä‘Ã£ táº¡o 3 script Python chi tiáº¿t vá»›i giáº£i thÃ­ch Ä‘áº§y Ä‘á»§ cho tá»«ng bÆ°á»›c cáº£i tiáº¿n:

---

1. ğŸ§¹ LÃ m sáº¡ch dá»¯ liá»‡u: Loáº¡i bá» giÃ¡ trá»‹ 1RM gáº§n báº±ng 0

Váº¥n Ä‘á» hiá»‡n táº¡i:

- Dataset cÃ³ 200 samples vá»›i 1RM tá»« 0.0 - 224.0 kg
- MAPE (Mean Absolute Percentage Error) = 6.15Ã—10Â¹â¸% - vÃ´ nghÄ©a do chia cho giÃ¡ trá»‹ gáº§n 0
- RÂ² = -0.356 - mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»‡ hÆ¡n trung bÃ¬nh

Giáº£i phÃ¡p trong data_cleaning.py:

- XÃ³a giÃ¡ trá»‹ zero vÃ  Ã¢m (loáº¡i bá» cÃ¡c máº«u khÃ´ng há»£p lá»‡)
- Loáº¡i bá» outliers báº±ng IQR method (Q1-1.5Ã—IQR, Q3+1.5Ã—IQR)
- Validate domain knowledge:
  - 1RM tá»‘i thiá»ƒu = 15-20kg (ngÆ°á»i lá»›n)
  - 1RM tá»‘i Ä‘a = 300kg (ngÆ°á»i nÃ¢ng cao)
  - Kiá»ƒm tra tÆ°Æ¡ng quan vá»›i cÃ¢n náº·ng vÃ  kinh nghiá»‡m
- Xá»­ lÃ½ missing values báº±ng median (chá»‘ng outliers)
- PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng data vá»›i visualizations

---

2. ğŸ—ï¸ TÃ¡ch mÃ´ hÃ¬nh: Huáº¥n luyá»‡n mÃ´ hÃ¬nh riÃªng cho má»—i tÃ¡c vá»¥

Váº¥n Ä‘á» vá»›i Multi-task Learning:

- Interference giá»¯a cÃ¡c tÃ¡c vá»¥: MÃ´ hÃ¬nh cá»‘ gáº¯ng tá»‘i Æ°u 3 Ä‘áº§u ra cÃ¹ng lÃºc
- KhÃ¡c biá»‡t Ä‘á»™ khÃ³: 1RM (khÃ³) vs Readiness (dá»…) vs Suitability (trung bÃ¬nh)
- Kiáº¿n trÃºc khÃ´ng tá»‘i Æ°u: CÃ¹ng má»™t kiáº¿n trÃºc cho 3 tÃ¡c vá»¥ khÃ¡c nhau

Giáº£i phÃ¡p trong specialized_models.py:

- Specialized1RMModel:
  - Feature extraction riÃªng cho 1RM (256 â†’ 128 â†’ 64)
  - Branch architecture: Body composition + Experience + SePA
  - Attention mechanism cho features quan trá»ng
  - Residual connections cho training stability
- SpecializedSuitabilityModel:
  - Enhanced MLP vá»›i GeLU activation
  - Auxiliary classifiers: Difficulty + Goal types
  - Batch normalization vÃ  dropout tá»‘i Æ°u
- SpecializedReadinessModel:
  - SePA-focused network (mood, fatigue, effort)
  - Physical factors network riÃªng biá»‡t
  - Fusion layer káº¿t há»£p hai luá»“ng thÃ´ng tin
- Training pipeline chuyÃªn biá»‡t cho tá»«ng mÃ´ hÃ¬nh vá»›i hyperparameters riÃªng

---

3. ğŸ“ˆ Biáº¿n Ä‘á»•i má»¥c tiÃªu: Ãp dá»¥ng Log Transform cho 1RM

Váº¥n Ä‘á» phÃ¢n phá»‘i 1RM:

- Skewed distribution: Skewness = 1.264 (phÃ¢n phá»‘i lá»‡ch pháº£i)
- Heteroscedasticity: PhÆ°Æ¡ng sai tÄƒng theo giÃ¡ trá»‹ 1RM
- Non-linear relationships: 1RM cÃ³ quan há»‡ non-linear vá»›i cÃ¡c features

Giáº£i phÃ¡p trong target_transformation.py:

- Log Transformation Options:
  - log1p(y) = log(1 + y): Chuáº©n nháº¥t
  - safe_log(y) = log(y + constant): TrÃ¡nh log(0)
  - log(y): Vá»›i clipping giÃ¡ trá»‹ Ã¢m
- Power Transformation:
  - Box-Cox: TÃ¬m Î» tá»‘i Æ°u Ä‘á»ƒ chuáº©n hÃ³a phÃ¢n phá»‘i
  - Yeo-Johnson: Xá»­ lÃ½ giÃ¡ trá»‹ Ã¢m vÃ  zero
  - Square Root: âˆšy cho giáº£m skewness
- Advanced Methods:
  - Quantile Transformation: Chuyá»ƒn thÃ nh phÃ¢n phá»‘i chuáº©n/uniform
  - Domain-Specific Transform: Dá»±a trÃªn kiáº¿n thá»©c exercise physiology
  - Auto-transformation: Tá»± Ä‘á»™ng chá»n phÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t

Evaluation Framework:

- Test táº¥t cáº£ transformations vá»›i Ridge Regression baseline
- Metrics: MAE, RMSE, RÂ², MAPE
- Automatic selection: Chá»n transformation cÃ³ MAPE tháº¥p nháº¥t
- Visual comparison: Histograms, Q-Q plots, metric comparisons

---

4. ğŸ”§ Cáº£i tiáº¿n kiáº¿n trÃºc: TÄƒng Ä‘á»™ phá»©c táº¡p cho 1RM

CÃ¡c ká»¹ thuáº­t Ä‘Ã£ implement:

A. Feature Engineering NÃ¢ng Cao:

# Body composition features

df['bmi_category'] = pd.cut(df['bmi'], bins=[0, 18.5, 25, 30, 100])

# Experience interactions

df['experience_intensity'] = df['experience_level'] _ df['workout_frequency']
df['age_experience_interaction'] = df['age'] _ df['experience_level']

# Strength potential

df['strength_potential'] = df['weight_kg'] _ (1 + df['experience_level'] _ 0.1)

B. Ensemble Methods:

- RandomForest (100 trees)
- GradientBoosting (100 estimators)
- XGBoost vá»›i regularization
- LightGBM vá»›i leaf-wise growth
- Best model selection tá»± Ä‘á»™ng

C. Neural Network Enhancements:

- Layer Normalization: Giáº£m internal covariate shift
- GeLU Activation: Smooth hÆ¡n ReLU
- Residual Connections: GiÃºp training deeper networks
- Dropout scheduling: Dropout giáº£m dáº§n theo epochs
- Gradient Clipping: NgÄƒn exploding gradients

D. Training Optimizations:

- AdamW optimizer vá»›i weight decay
- Learning Rate Scheduling: ReduceLROnPlateau
- Early Stopping: Dá»«ng khi validation khÃ´ng cáº£i thiá»‡n
- Batch Normalization: Stabilize training dynamics

---

ğŸš€ CÃ¡ch sá»­ dá»¥ng cÃ¡c script:

1. Cháº¡y Data Cleaning:

cd ai_server/model/src/v3
python data_cleaning.py --input ./data/enhanced_gym_member_exercise_tracking_10k.xlsx

2. TÃ¬m Best Target Transformation:

python target_transformation.py --data ./data/test_dataset.xlsx --target estimated_1rm --visualize

3. Huáº¥n luyá»‡n Models ChuyÃªn biá»‡t:

python specialized_models.py --data ./enhanced_gym_member_exercise_tracking_10k_cleaned.xlsx --output
./specialized_models

4. Deploy vá»›i Best Configuration:

# Ãp dá»¥ng transformation tá»‘t nháº¥t

transformer = TargetTransformer()
y_transformed, method, params = transformer.apply_best_transformation(y_1rm, X_train)

# Huáº¥n luyá»‡n vá»›i architecture má»›i

model = Specialized1RMModel(input_dim=len(features))

# ... training loop ...

ğŸ“Š Káº¿t quáº£ ká»³ vá»ng:

1. 1RM Prediction:


    - MAE giáº£m tá»« 40.3kg â†’ dÆ°á»›i 15kg
    - RÂ² cáº£i thiá»‡n tá»« -0.356 â†’ trÃªn 0.6
    - MAPE tá»« vÃ´ háº¡n â†’ dÆ°á»›i 20%

2. Suitability Prediction:


    - Giá»¯ vá»¯ng accuracy >95%
    - Cáº£i thiá»‡n RÂ² tá»« Ã¢m â†’ dÆ°Æ¡ng

3. Readiness Prediction:


    - Duy trÃ¬ accuracy ~100%
    - Cáº£i thiá»‡n RÂ² tá»« 0.012 â†’ trÃªn 0.3

CÃ¡c script nÃ y cung cáº¥p complete framework Ä‘á»ƒ cáº£i tiáº¿n tá»«ng bÆ°á»›c má»™t cÃ¡ch há»‡ thá»‘ng vÃ  cÃ³ Ä‘o lÆ°á»ng rÃµ
rÃ ng! ğŸ‰
