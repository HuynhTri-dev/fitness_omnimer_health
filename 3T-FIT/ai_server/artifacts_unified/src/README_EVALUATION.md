# Model Evaluation Guide

HÆ°á»›ng dáº«n Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh AI cho há»‡ thá»‘ng gá»£i Ã½ bÃ i táº­p vÃ  dá»± Ä‘oÃ¡n cÆ°á»ng Ä‘á»™ táº­p luyá»‡n.

## ğŸ“‹ Tá»•ng quan

CÃ³ 2 loáº¡i model cáº§n Ä‘Ã¡nh giÃ¡:

1. **Exercise Recommendation Model** - Model gá»£i Ã½ bÃ i táº­p vá»›i exercise embeddings
2. **Multi-Task Learning (MTL) Model** - Model Ä‘a nhiá»‡m vá»¥ (classification + regression)

## ğŸ¯ CÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ (Metrics)

### Classification Task (Gá»£i Ã½ bÃ i táº­p)

| Metric          | Ã nghÄ©a                                         | Target | Excellent |
| --------------- | ----------------------------------------------- | ------ | --------- |
| **Precision@5** | Tá»· lá»‡ bÃ i táº­p Ä‘Æ°á»£c gá»£i Ã½ Ä‘Ãºng trong Top 5       | â‰¥ 0.70 | â‰¥ 0.85    |
| **Recall@5**    | Tá»· lá»‡ bÃ i táº­p phÃ¹ há»£p Ä‘Æ°á»£c tÃ¬m tháº¥y trong Top 5 | â‰¥ 0.60 | â‰¥ 0.75    |
| **F1-Score@5**  | Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall     | â‰¥ 0.65 | â‰¥ 0.80    |

### Regression Task (Dá»± Ä‘oÃ¡n cÆ°á»ng Ä‘á»™)

| Metric   | Parameter         | Target             | Excellent |
| -------- | ----------------- | ------------------ | --------- |
| **MAE**  | Sets (sá»‘ hiá»‡p)    | â‰¤ 0.5              | â‰¤ 0.3     |
| **MAE**  | Reps (sá»‘ láº§n láº·p) | â‰¤ 2.0              | â‰¤ 1.0     |
| **MAE**  | Load (kg)         | â‰¤ 5.0              | â‰¤ 3.0     |
| **RMSE** | Táº¥t cáº£ parameters | CÃ ng tháº¥p cÃ ng tá»‘t | -         |
| **RÂ²**   | Táº¥t cáº£ parameters | â‰¥ 0.70             | â‰¥ 0.85    |

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. ÄÃ¡nh giÃ¡ Exercise Recommendation Model

```bash
cd ai_server/artifacts_unified/src

# Sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n máº·c Ä‘á»‹nh
python evaluate_exercise_model.py

# Hoáº·c chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n cá»¥ thá»ƒ
python evaluate_exercise_model.py \
    --model_path ../artifacts_exercise_rec/best_model.pt \
    --test_data ../../../Data/data/merged_omni_health_dataset.xlsx \
    --artifacts ../artifacts_exercise_rec
```

**Output máº«u:**

```
================================================================================
EXERCISE RECOMMENDATION MODEL EVALUATION
================================================================================

[1/6] Loading metadata from: ../artifacts_exercise_rec/metadata.json
  âœ“ Model trained on: 2025-11-20T12:30:45
  âœ“ Number of exercises: 66

[2/6] Loaded preprocessor from: ../artifacts_exercise_rec/preprocessor.joblib

[3/6] Loading test data from: ../../../Data/data/merged_omni_health_dataset.xlsx
  âœ“ Loaded 204 test samples

[4/6] Loading model from: ../artifacts_exercise_rec/best_model.pt
  âœ“ Model loaded (epoch 85)

[5/6] Running evaluation...

[6/6] Evaluation Results:
================================================================================

ğŸ“Š CLASSIFICATION METRICS (Exercise Recommendation)
--------------------------------------------------------------------------------
  Precision@5:  0.7823
  Recall@5:     0.6541
  F1-Score@5:   0.7123
  Precision@10: 0.7234
  Recall@10:    0.7012
  F1-Score@10:  0.7121

ğŸ“ˆ REGRESSION METRICS (Intensity Parameters)
--------------------------------------------------------------------------------
Parameter       MAE          RMSE         RÂ²           Samples
--------------------------------------------------------------------------------
sets            0.3245       0.4521       0.8234       195
reps            1.2341       1.8923       0.7823       195
kg              2.8934       4.1234       0.8512       180
km              0.4523       0.6234       0.7234       24
min             3.2341       5.1234       0.7923       204
minRest         0.2341       0.3456       0.6234       150
avgHR           5.2341       8.1234       0.7512       180
peakHR          6.3412       9.2341       0.7234       180

âœ… Evaluation completed!
Results saved to: ../artifacts_exercise_rec/evaluation_results.json
================================================================================
```

### 2. ÄÃ¡nh giÃ¡ MTL Model

```bash
cd ai_server/artifacts_unified/src

# Sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n máº·c Ä‘á»‹nh
python evaluate_mtl_model.py

# Hoáº·c chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n cá»¥ thá»ƒ
python evaluate_mtl_model.py \
    --model_path ../artifacts_omni_mlbce/best.pt \
    --test_data ../data/merged_omni_health_dataset.xlsx \
    --artifacts ../artifacts_omni_mlbce
```

**Output máº«u:**

```
================================================================================
MULTI-TASK LEARNING (MTL) MODEL EVALUATION
================================================================================

[1/6] Loading metadata from: ../artifacts_omni_mlbce/meta.json
  âœ“ Number of exercises: 200
  âœ“ Input dimension: 15

[2/6] Loaded preprocessor from: ../artifacts_omni_mlbce/preprocessor.joblib

[3/6] Loading test data from: ../data/merged_omni_health_dataset.xlsx
  âœ“ Loaded 204 test samples

[4/6] Loading model from: ../artifacts_omni_mlbce/best.pt
  âœ“ Model loaded successfully

[5/6] Running evaluation...

[6/6] Evaluation Results:
================================================================================

ğŸ“Š CLASSIFICATION METRICS (Exercise Recommendation)
--------------------------------------------------------------------------------
  Precision@5:  0.8123
  Recall@5:     0.6823
  F1-Score@5:   0.7412
  Precision@10: 0.7534
  Recall@10:    0.7234
  F1-Score@10:  0.7381

ğŸ“ˆ REGRESSION METRICS (Intensity Parameters)
--------------------------------------------------------------------------------
Parameter       MAE          RMSE         RÂ²           Samples
--------------------------------------------------------------------------------
sets            0.2834       0.3921       0.8634       195
reps            1.0234       1.5234       0.8234       195
load_kg         2.3412       3.4521       0.8823       180

ğŸ¯ PERFORMANCE ASSESSMENT
--------------------------------------------------------------------------------
  Classification P@5: 0.8123 - âœ… Good
  Classification R@5: 0.6823 - âœ… Good
  Regression Sets MAE: 0.2834 - ğŸŒŸ Excellent
  Regression Reps MAE: 1.0234 - ğŸŒŸ Excellent
  Regression Load MAE: 2.3412 kg - ğŸŒŸ Excellent

âœ… Evaluation completed!
Results saved to: ../artifacts_omni_mlbce/evaluation_results.json
================================================================================
```

## ğŸ“Š Káº¿t quáº£ Ä‘áº§u ra

Sau khi cháº¡y evaluation, file `evaluation_results.json` sáº½ Ä‘Æ°á»£c táº¡o ra vá»›i cáº¥u trÃºc:

```json
{
  "classification": {
    "precision@5": 0.8123,
    "recall@5": 0.6823,
    "f1@5": 0.7412,
    "precision@10": 0.7534,
    "recall@10": 0.7234,
    "f1@10": 0.7381
  },
  "regression": {
    "sets": {
      "mae": 0.2834,
      "rmse": 0.3921,
      "r2": 0.8634,
      "n_samples": 195
    },
    "reps": {
      "mae": 1.0234,
      "rmse": 1.5234,
      "r2": 0.8234,
      "n_samples": 195
    },
    "load_kg": {
      "mae": 2.3412,
      "rmse": 3.4521,
      "r2": 0.8823,
      "n_samples": 180
    }
  },
  "test_samples": 204,
  "model_path": "../artifacts_omni_mlbce/best.pt",
  "test_data_path": "../data/merged_omni_health_dataset.xlsx"
}
```

## ğŸ” PhÃ¢n tÃ­ch káº¿t quáº£

### Giáº£i thÃ­ch cÃ¡c metrics

#### **Precision@K**

- Äo lÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c gá»£i Ã½
- CÃ´ng thá»©c: `TP / (TP + FP)`
- VÃ­ dá»¥: Precision@5 = 0.80 nghÄ©a lÃ  80% trong 5 bÃ i táº­p Ä‘Æ°á»£c gá»£i Ã½ lÃ  phÃ¹ há»£p

#### **Recall@K**

- Äo lÆ°á»ng Ä‘á»™ bao phá»§ cá»§a cÃ¡c gá»£i Ã½
- CÃ´ng thá»©c: `TP / (TP + FN)`
- VÃ­ dá»¥: Recall@5 = 0.70 nghÄ©a lÃ  70% bÃ i táº­p phÃ¹ há»£p Ä‘Æ°á»£c tÃ¬m tháº¥y trong Top 5

#### **F1-Score@K**

- Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
- CÃ´ng thá»©c: `2 * (P * R) / (P + R)`
- CÃ¢n báº±ng giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ bao phá»§

#### **MAE (Mean Absolute Error)**

- Sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh
- CÃ´ng thá»©c: `Î£|y_pred - y_true| / n`
- VÃ­ dá»¥: MAE = 1.5 reps nghÄ©a lÃ  trung bÃ¬nh sai lá»‡ch 1.5 láº§n láº·p

#### **RMSE (Root Mean Square Error)**

- CÄƒn báº­c hai cá»§a sai sá»‘ bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh
- CÃ´ng thá»©c: `âˆš(Î£(y_pred - y_true)Â² / n)`
- Pháº¡t náº·ng hÆ¡n cÃ¡c sai sá»‘ lá»›n

#### **RÂ² Score**

- Há»‡ sá»‘ xÃ¡c Ä‘á»‹nh - Ä‘o má»©c Ä‘á»™ phÃ¹ há»£p cá»§a mÃ´ hÃ¬nh
- GiÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1 (1 lÃ  hoÃ n háº£o)
- RÂ² = 0.85 nghÄ©a lÃ  mÃ´ hÃ¬nh giáº£i thÃ­ch Ä‘Æ°á»£c 85% phÆ°Æ¡ng sai cá»§a dá»¯ liá»‡u

### Khi nÃ o cáº§n cáº£i thiá»‡n model?

âš ï¸ **Cáº§n cáº£i thiá»‡n náº¿u:**

- Precision@5 < 0.70
- Recall@5 < 0.60
- MAE (Sets) > 0.5
- MAE (Reps) > 2.0
- MAE (Load) > 5.0 kg
- RÂ² < 0.70

âœ… **Model tá»‘t náº¿u:**

- 0.70 â‰¤ Precision@5 < 0.85
- 0.60 â‰¤ Recall@5 < 0.75
- 0.3 < MAE (Sets) â‰¤ 0.5
- 1.0 < MAE (Reps) â‰¤ 2.0
- 3.0 < MAE (Load) â‰¤ 5.0 kg
- 0.70 â‰¤ RÂ² < 0.85

ğŸŒŸ **Model xuáº¥t sáº¯c náº¿u:**

- Precision@5 â‰¥ 0.85
- Recall@5 â‰¥ 0.75
- MAE (Sets) â‰¤ 0.3
- MAE (Reps) â‰¤ 1.0
- MAE (Load) â‰¤ 3.0 kg
- RÂ² â‰¥ 0.85

## ğŸ› ï¸ Troubleshooting

### Lá»—i: "File not found"

```bash
# Kiá»ƒm tra Ä‘Æ°á»ng dáº«n
ls ../artifacts_exercise_rec/best_model.pt
ls ../../../Data/data/merged_omni_health_dataset.xlsx
```

### Lá»—i: "Module not found"

```bash
# Äáº£m báº£o Ä‘ang á»Ÿ Ä‘Ãºng thÆ° má»¥c
cd ai_server/artifacts_unified/src

# Hoáº·c thÃªm PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### Lá»—i: "CUDA out of memory"

```python
# Trong script, thay Ä‘á»•i:
device = torch.device('cpu')  # Thay vÃ¬ 'cuda'
```

## ğŸ“š Tham kháº£o

- [Workflow Training](../../workflow.md) - Quy trÃ¬nh training model
- [README Exercise Recommendation](README_EXERCISE_REC.md) - Chi tiáº¿t vá» Exercise Recommendation Model
- [Scikit-learn Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) - TÃ i liá»‡u vá» metrics
