"""
Script ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu test dataset v·ªõi chu·∫©n h√≥a SePA v√† t√≠nh to√°n 1RM
- Chu·∫©n h√≥a c√°c c·ªôt SePA (mood, fatigue, effort) v·ªÅ thang ƒëi·ªÉm 1-5
- T√≠nh to√°n estimated_1rm s·ª≠ d·ª•ng c√¥ng th·ª©c Epley
- √Åp d·ª•ng c√°c x·ª≠ l√Ω t∆∞∆°ng t·ª± nh∆∞ preprocessing_own_dataset.py

Author: Claude Code Assistant
Date: 2025-11-25
"""

import pandas as pd
import numpy as np
from pathlib import Path

# ==================== SEPA MAPPING FUNCTIONS ====================

# Mapping cho c√°c gi√° tr·ªã SePA t·ª´ text sang s·ªë (1-5)
MOOD_MAPPING = {
    'Very Bad': 1,
    'Bad': 2,
    'Neutral': 3,
    'Good': 4,
    'Very Good': 5,
    'Excellent': 5,
    # C√°c gi√° tr·ªã c√≥ th·ªÉ c√≥ kh√°c
    'R·∫•t t·ªá': 1,
    'T·ªá': 2,
    'B√¨nh th∆∞·ªùng': 3,
    'T·ªët': 4,
    'R·∫•t t·ªët': 5,
    'Tuy·ªát v·ªùi': 5
}

FATIGUE_MAPPING = {
    'Very Low': 1,
    'Low': 2,
    'Medium': 3,
    'High': 4,
    'Very High': 5,
    # C√°c gi√° tr·ªã c√≥ th·ªÉ c√≥ kh√°c
    'R·∫•t th·∫•p': 1,
    'Th·∫•p': 2,
    'Trung b√¨nh': 3,
    'Cao': 4,
    'R·∫•t cao': 5
}

EFFORT_MAPPING = {
    'Very Low': 1,
    'Low': 2,
    'Medium': 3,
    'High': 4,
    'Very High': 5,
    # C√°c gi√° tr·ªã c√≥ th·ªÉ c√≥ kh√°c
    'R·∫•t th·∫•p': 1,
    'Th·∫•p': 2,
    'Trung b√¨nh': 3,
    'Cao': 4,
    'R·∫•t cao': 5
}

def map_sepa_to_numeric(value, mapping_dict, default_value=3):
    """
    Chuy·ªÉn ƒë·ªïi gi√° tr·ªã SePA t·ª´ text sang s·ªë (1-5)

    Args:
        value: Gi√° tr·ªã c·∫ßn chuy·ªÉn ƒë·ªïi (c√≥ th·ªÉ l√† text, s·ªë, ho·∫∑c NaN)
        mapping_dict: Dictionary mapping t∆∞∆°ng ·ª©ng
        default_value: Gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng th·ªÉ mapping (3 = Neutral/Medium)

    Returns:
        int: Gi√° tr·ªã s·ªë t·ª´ 1-5
    """
    if pd.isna(value):
        return default_value

    # N·∫øu ƒë√£ l√† s·ªë, ki·ªÉm tra v√† tr·∫£ v·ªÅ
    try:
        num_val = int(float(value))
        if 1 <= num_val <= 5:
            return num_val
    except (ValueError, TypeError):
        pass

    # N·∫øu l√† string, th·ª≠ mapping
    if isinstance(value, str):
        value_str = value.strip()

        # Th·ª≠ direct mapping
        if value_str in mapping_dict:
            return mapping_dict[value_str]

        # Th·ª≠ case-insensitive matching
        for key, val in mapping_dict.items():
            if key.lower() == value_str.lower():
                return val

        # Th·ª≠ mapping theo t·ª´ kh√≥a
        value_lower = value_str.lower()
        for key, val in mapping_dict.items():
            if key.lower() in value_lower or value_lower in key.lower():
                return val

    return default_value

def standardize_sepa_columns(df):
    """
    Chu·∫©n h√≥a c√°c c·ªôt SePA v·ªÅ thang ƒëi·ªÉm 1-5

    Args:
        df: DataFrame ch·ª©a c√°c c·ªôt SePA

    Returns:
        DataFrame v·ªõi c√°c c·ªôt SePA ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a
    """
    sepa_columns = ['mood', 'fatigue', 'effort']

    for col in sepa_columns:
        if col in df.columns:
            print(f"\nChu·∫©n h√≥a c·ªôt {col}...")

            # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ c·ªôt tr∆∞·ªõc khi chu·∫©n h√≥a
            unique_values = df[col].dropna().unique()
            print(f"  - Gi√° tr·ªã duy nh·∫•t tr∆∞·ªõc chu·∫©n h√≥a: {list(unique_values[:10])}{'...' if len(unique_values) > 10 else ''}")

            # Ch·ªçn mapping dictionary t∆∞∆°ng ·ª©ng
            if col == 'mood':
                mapping_dict = MOOD_MAPPING
            elif col == 'fatigue':
                mapping_dict = FATIGUE_MAPPING
            elif col == 'effort':
                mapping_dict = EFFORT_MAPPING
            else:
                continue

            # √Åp d·ª•ng mapping
            original_col = df[col].copy()
            df[col] = df[col].apply(lambda x: map_sepa_to_numeric(x, mapping_dict))

            # Th·ªëng k√™ k·∫øt qu·∫£
            changed_count = (original_col != df[col]).sum()
            print(f"  - ƒê√£ chu·∫©n h√≥a {changed_count} gi√° tr·ªã")
            print(f"  - Ph√¢n ph·ªëi sau chu·∫©n h√≥a: {df[col].value_counts().sort_index().to_dict()}")
        else:
            print(f"\nKh√¥ng t√¨m th·∫•y c·ªôt {col}")

    return df

# ==================== 1RM CALCULATION ====================

def calculate_1rm(weight, reps):
    """
    T√≠nh 1RM ∆∞·ªõc t√≠nh theo c√¥ng th·ª©c Epley: 1RM = Weight * (1 + Reps/30)

    Args:
        weight: C√¢n n·∫∑ng (kg)
        reps: S·ªë l·∫ßn l·∫∑p

    Returns:
        float: 1RM ∆∞·ªõc t√≠nh
    """
    if weight == 0 or reps == 0:
        return 0.0
    return weight * (1 + reps / 30)

def extract_intensity_with_1rm(row):
    """
    T√≠nh to√°n c√°c ch·ªâ s·ªë nƒÉng l·ª±c bao g·ªìm c·∫£ 1RM

    Args:
        row: D√≤ng d·ªØ li·ªáu workout

    Returns:
        Series v·ªõi c√°c metrics: estimated_1rm, pace, duration_capacity, rest_period, intensity_score
    """
    result = {
        'estimated_1rm': 0.0,
        'pace': 0.0,
        'duration_capacity': 0.0,
        'rest_period': 0.0,
        'intensity_score': 0.0
    }

    # 1. X·ª≠ l√Ω Strength: sets/reps/weight/timeresteachset
    if pd.notna(row.get('sets/reps/weight/timeresteachset')):
        try:
            data = str(row['sets/reps/weight/timeresteachset'])
            sets = data.replace('|', ',').split(',')
            max_1rm = 0
            max_rest = 0
            has_valid_set = False

            for s in sets:
                parts = s.strip().lower().split('x')
                if len(parts) >= 2:
                    try:
                        reps = float(parts[0])
                        weight = float(parts[1])

                        # Parse Rest n·∫øu c√≥ (th√†nh ph·∫ßn th·ª© 3)
                        if len(parts) >= 3:
                            rest = float(parts[2])
                            if rest > max_rest:
                                max_rest = rest

                        # Ch·ªâ t√≠nh n·∫øu weight > 0 (b√†i t·∫≠p t·∫°)
                        if weight > 0:
                            rm = calculate_1rm(weight, reps)
                            if rm > max_1rm:
                                max_1rm = rm
                            has_valid_set = True
                    except ValueError:
                        continue

            if has_valid_set and max_1rm > 0:
                result['estimated_1rm'] = round(max_1rm, 2)

            if max_rest > 0:
                result['rest_period'] = round(max_rest, 2)

        except Exception:
            pass

    # 2. X·ª≠ l√Ω Static/Endurance: sets/time_m/timeresteachset
    if pd.notna(row.get('sets/time_m/timeresteachset')):
        try:
            data = str(row['sets/time_m/timeresteachset'])
            sets = data.replace('|', ',').split(',')
            max_duration = 0
            max_rest = 0

            for s in sets:
                parts = s.strip().lower().split('x')
                if len(parts) >= 2:
                    try:
                        val1 = float(parts[0])
                        val2 = float(parts[1])

                        if len(parts) == 3:
                            # 3x60x30 -> Sets x Duration x Rest
                            duration = val2
                            rest = float(parts[2])
                        else:
                            # 60x30 -> Duration x Rest
                            duration = val1
                            rest = val2

                        if duration > max_duration:
                            max_duration = duration
                        if rest > max_rest:
                            max_rest = rest

                    except ValueError:
                        continue

            if max_duration > 0:
                result['duration_capacity'] = round(max_duration, 2)

            # Update rest n·∫øu l·ªõn h∆°n gi√° tr·ªã hi·ªán t·∫°i
            if max_rest > 0 and max_rest > result['rest_period']:
                result['rest_period'] = round(max_rest, 2)

        except Exception:
            pass

    # 3. X·ª≠ l√Ω Cardio Distance
    if pd.notna(row.get('distance_km')) and row.get('distance_km') > 0:
        if pd.notna(row.get('session_duration')) and row.get('session_duration') > 0:
            speed = row['distance_km'] / row['session_duration']
            result['pace'] = round(speed, 2)

    # 4. Fallback: Intensity Score
    if pd.notna(row.get('intensity')):
        result['intensity_score'] = round(row['intensity'], 2)

    return pd.Series(result)

# ==================== MAIN PROCESSING FUNCTION ====================

def clean_test_dataset(df: pd.DataFrame) -> pd.DataFrame:
    """
    L√†m s·∫°ch d·ªØ li·ªáu test v·ªõi SePA standardization v√† 1RM calculation

    Args:
        df: DataFrame c·∫ßn x·ª≠ l√Ω

    Returns:
        DataFrame ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch v√† chu·∫©n h√≥a
    """
    print(f"S·ªë l∆∞·ª£ng d√≤ng ban ƒë·∫ßu: {len(df)}")
    print(f"S·ªë l∆∞·ª£ng c·ªôt ban ƒë·∫ßu: {len(df.columns)}")
    print(f"T√™n c√°c c·ªôt ban ƒë·∫ßu: {list(df.columns)}\n")

    # T·∫°o b·∫£n sao ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng d·ªØ li·ªáu g·ªëc
    df_cleaned = df.copy()

    # B∆∞·ªõc 1: Lo·∫°i b·ªè c√°c c·ªôt r·ªóng
    empty_columns = []
    for col in df_cleaned.columns:
        if df_cleaned[col].isna().all() or (df_cleaned[col].astype(str).str.strip() == '').all():
            empty_columns.append(col)

    if empty_columns:
        print(f"Lo·∫°i b·ªè {len(empty_columns)} c·ªôt r·ªóng: {empty_columns}")
        df_cleaned = df_cleaned.drop(columns=empty_columns)

    # B∆∞·ªõc 2: Chu·∫©n h√≥a c√°c c·ªôt SePA
    print("\n" + "="*50)
    print("CHU·∫®N H√ìA C√ÅC C·ªòT SEPA (1-5 SCALE)")
    print("="*50)
    df_cleaned = standardize_sepa_columns(df_cleaned)

    # B∆∞·ªõc 3: X√≥a c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt (nh∆∞ng GI·ªÆ c√°c c·ªôt SePA)
    columns_to_drop = [
        'checkup_date', 'id', 'recovery_h', 'effectiveness',
        'equipment', 'target_muscle', 'secondary_muscles', 'bodypart_target',
        'workout_goal_achieved', 'target_muscle_felt', 'category_exercise_want_todo', 'birthday',
        'whr', 'workout_date', 'exercise_not_suitable', 'activity_level', 'suitability_y', 
        'user_health_profile_id', 'workout_id', 'user_id'
    ]

    existing_columns_to_drop = [col for col in columns_to_drop if col in df_cleaned.columns]

    if existing_columns_to_drop:
        print(f"\nX√≥a c√°c c·ªôt: {existing_columns_to_drop}")
        df_cleaned = df_cleaned.drop(columns=existing_columns_to_drop)

    # B∆∞·ªõc 4: Lo·∫°i b·ªè c√°c d√≤ng c√≥ done = 0
    if 'done' in df_cleaned.columns:
        rows_before = len(df_cleaned)
        df_cleaned = df_cleaned[df_cleaned['done'] != 0]
        rows_removed = rows_before - len(df_cleaned)
        print(f"\nLo·∫°i b·ªè {rows_removed} d√≤ng c√≥ done = 0")
        df_cleaned = df_cleaned.drop(columns=['done'])

    # B∆∞·ªõc 5: ƒê·ªïi t√™n v√† chuy·ªÉn ƒë·ªïi total_duration_min
    if 'total_duration_min' in df_cleaned.columns:
        df_cleaned['session_duration'] = (df_cleaned['total_duration_min'] / 60).round(2)
        df_cleaned = df_cleaned.drop(columns=['total_duration_min'])
        print("\nƒê√£ ƒë·ªïi t√™n 'total_duration_min' th√†nh 'session_duration' (gi·ªù)")

    # B∆∞·ªõc 6: Bi·∫øn ƒë·ªïi experience_level v√† intensity
    experience_map = {
        'beginner': 1,
        'intermediate': 2,
        'advanced': 3,
        'expert': 4
    }

    if 'experience_level' in df_cleaned.columns:
        df_cleaned['experience_level'] = df_cleaned['experience_level'].astype(str).str.lower().map(experience_map)
        print(f"\nƒê√£ bi·∫øn ƒë·ªïi c·ªôt 'experience_level' sang d·∫°ng s·ªë")

    intensity_map = {
        'low': 1,
        'medium': 2,
        'high': 3,
        'maximal': 4
    }

    if 'intensity' in df_cleaned.columns:
        df_cleaned['intensity'] = df_cleaned['intensity'].astype(str).str.lower().map(intensity_map)
        print(f"ƒê√£ bi·∫øn ƒë·ªïi c·ªôt 'intensity' sang d·∫°ng s·ªë")

    # B∆∞·ªõc 7: T√≠nh to√°n c√°c ch·ªâ s·ªë nƒÉng l·ª±c (bao g·ªìm 1RM)
    print("\n" + "="*50)
    print("T√çNH TO√ÅN C√ÅC CH·ªà S·ªê NƒÇNG L·ª∞C (1RM, PACE, DURATION)")
    print("="*50)

    intensity_metrics = df_cleaned.apply(extract_intensity_with_1rm, axis=1)
    df_cleaned = pd.concat([df_cleaned, intensity_metrics], axis=1)

    # X√≥a c√°c c·ªôt c≈© kh√¥ng c·∫ßn thi·∫øt
    cols_to_remove = [
        'sets/reps/weight/timeresteachset',
        'sets/time_m/timeresteachset',
        'distance_km',
        'intensity'
    ]
    existing_cols_to_remove = [col for col in cols_to_remove if col in df_cleaned.columns]

    if existing_cols_to_remove:
        df_cleaned = df_cleaned.drop(columns=existing_cols_to_remove)
        print(f"ƒê√£ x√≥a c√°c c·ªôt c≈©: {existing_cols_to_remove}")

    # B∆∞·ªõc 8: ƒê·ªïi t√™n category_type_want_todo th√†nh workout_type
    if 'category_type_want_todo' in df_cleaned.columns:
        df_cleaned = df_cleaned.rename(columns={'category_type_want_todo': 'workout_type'})
        print("\nƒê√£ ƒë·ªïi t√™n 'category_type_want_todo' th√†nh 'workout_type'")

    # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ 1RM
    if 'estimated_1rm' in df_cleaned.columns:
        non_zero_1rm = df_cleaned[df_cleaned['estimated_1rm'] > 0]
        print(f"\nTh√¥ng tin 1RM:")
        print(f"  - S·ªë b√†i t·∫≠p c√≥ 1RM > 0: {len(non_zero_1rm)}/{len(df_cleaned)}")
        if len(non_zero_1rm) > 0:
            print(f"  - 1RM min: {non_zero_1rm['estimated_1rm'].min():.2f} kg")
            print(f"  - 1RM max: {non_zero_1rm['estimated_1rm'].max():.2f} kg")
            print(f"  - 1RM mean: {non_zero_1rm['estimated_1rm'].mean():.2f} kg")
            print(f"  - Sample 1RM values: {non_zero_1rm['estimated_1rm'].head().tolist()}")

    # Hi·ªÉn th·ªã th·ªëng k√™ SePA cu·ªëi c√πng
    print(f"\nTh·ªëng k√™ SePA cu·ªëi c√πng:")
    for col in ['mood', 'fatigue', 'effort']:
        if col in df_cleaned.columns:
            stats = df_cleaned[col].value_counts().sort_index()
            print(f"  - {col}: {stats.to_dict()}")

    print(f"\nK·∫øt qu·∫£ x·ª≠ l√Ω:")
    print(f"  - S·ªë d√≤ng cu·ªëi c√πng: {len(df_cleaned)}")
    print(f"  - S·ªë c·ªôt cu·ªëi c√πng: {len(df_cleaned.columns)}")
    print(f"  - C√°c c·ªôt: {list(df_cleaned.columns)}")

    return df_cleaned


def process_test_dataset(input_file: str, output_file: str = None) -> pd.DataFrame:
    """
    X·ª≠ l√Ω dataset test v·ªõi SePA standardization v√† 1RM calculation

    Args:
        input_file: ƒê∆∞·ªùng d·∫´n file input
        output_file: ƒê∆∞·ªùng d·∫´n file output (t·ª± ƒë·ªông t·∫°o n·∫øu kh√¥ng cung c·∫•p)

    Returns:
        DataFrame ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
    """
    print(f"ƒê·ªçc d·ªØ li·ªáu test t·ª´: {input_file}")
    df = pd.read_excel(input_file)

    print("\n" + "="*60)
    print("X·ª¨ L√ù TEST DATASET V·ªöI SEPA STANDARDIZATION & 1RM")
    print("="*60 + "\n")

    df_processed = clean_test_dataset(df)

    if output_file is None:
        input_path = Path(input_file)
        output_file = input_path.parent / f"{input_path.stem}_processed{input_path.suffix}"

    print(f"\n" + "="*60)
    print(f"L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√†o: {output_file}")
    print("="*60)

    df_processed.to_excel(output_file, index=False)

    # L∆∞u b√°o c√°o x·ª≠ l√Ω
    report_file = str(output_file).replace('.xlsx', '_processing_report.json')
    processing_report = {
        'input_file': input_file,
        'output_file': str(output_file),
        'processing_date': '2025-11-25',
        'records': {
            'input_count': len(df),
            'output_count': len(df_processed),
            'removed_count': len(df) - len(df_processed)
        },
        'sepa_standardization': {
            'mood_mapping': MOOD_MAPPING,
            'fatigue_mapping': FATIGUE_MAPPING,
            'effort_mapping': EFFORT_MAPPING
        },
        'columns': {
            'input_columns': list(df.columns),
            'output_columns': list(df_processed.columns)
        },
        'statistics': {
            'workout_types': df_processed['workout_type'].value_counts().to_dict() if 'workout_type' in df_processed.columns else {},
            'estimated_1rm_stats': {
                'mean': float(df_processed['estimated_1rm'].mean()) if 'estimated_1rm' in df_processed.columns else 0,
                'max': float(df_processed['estimated_1rm'].max()) if 'estimated_1rm' in df_processed.columns else 0,
                'non_zero_count': int(len(df_processed[df_processed['estimated_1rm'] > 0])) if 'estimated_1rm' in df_processed.columns else 0
            }
        }
    }

    import json
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(processing_report, f, indent=2, ensure_ascii=False)

    print(f"B√°o c√°o x·ª≠ l√Ω ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {report_file}")

    return df_processed


if __name__ == "__main__":
    # C·∫•u ƒë∆∞·ªùng d·∫´n file
    input_file = "./data/merged_omni_health_dataset.xlsx"  # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y n·∫øu c·∫ßn
    output_file = "./preprocessing_data/test_dataset.xlsx"

    # Ki·ªÉm tra file input
    if Path(input_file).exists():
        df_processed = process_test_dataset(input_file, output_file)
        print("\n‚úÖ Ho√†n th√†nh x·ª≠ l√Ω test dataset!")
        print(f"üìä Dataset ƒë√£ x·ª≠ l√Ω: {len(df_processed)} records")
    else:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {input_file}")
        print("Vui l√≤ng c·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n file trong script")
        print("Ho·∫∑c ƒë·∫∑t file test dataset v√†o th∆∞ m·ª•c data/")

        # Hi·ªÉn th·ªã c√°c file c√≥ s·∫µn trong th∆∞ m·ª•c data
        data_dir = Path("./data")
        if data_dir.exists():
            print(f"\nC√°c file c√≥ s·∫µn trong th∆∞ m·ª•c {data_dir}:")
            for file in data_dir.glob("*.xlsx"):
                print(f"  - {file.name}")